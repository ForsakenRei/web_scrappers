{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import nest_asyncio\n",
    "import pyppeteer\n",
    "\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import requests\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'H:/ASMR/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_list = os.listdir(file_path)\n",
    "current_list = pd.DataFrame(current_list)\n",
    "current_list.columns = ['Path_Name']\n",
    "current_list['RJ_Code'] = current_list['Path_Name'].str.extract('(RJ\\d{6})', expand=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_file = './archive_list_2022-02-20.xlsx'\n",
    "old_list = pd.read_excel(old_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_list = current_list[~current_list['RJ_Code'].isin(old_list['RJ_Code'])].reset_index().drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_list = []\n",
    "\n",
    "def dlsite_info_extract(archive_list):      \n",
    "    URL = 'https://www.dlsite.com/maniax/work/=/product_id/{}.html'.format(search_code)\n",
    "    page = requests.get(URL)\n",
    "    page_source = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "    try:\n",
    "        work_name = page_source.find('h1', id = 'work_name').text\n",
    "        work_genre = page_source.find('span', {'class' : re.compile('icon_(GEN|ADL|R15)')}).text\n",
    "        brand_name = page_source.find('span', {'class' : 'maker_name'}).text.replace('\\n', '')\n",
    "        work_cv = page_source.find('th', text = '声優').find_next_sibling('td').text\n",
    "        work_cv = re.sub(r'\\s', '', work_cv)   \n",
    "        release_date = page_source.find('th', text = '販売日').find_next_sibling('td').text.replace('年', '/').replace('月', '/').replace('日', '')\n",
    "        work_tag = page_source.find('th', text = 'ジャンル').find_next_sibling('td').text.replace('\\n', ' ').strip().replace(' ', ',')\n",
    "    except:\n",
    "        work_tag = 'None'\n",
    "\n",
    "    work_info = {}\n",
    "\n",
    "    work_info['RJ_Code'] = search_code\n",
    "    work_info['Brand_Name'] = brand_name\n",
    "    work_info['Work_Name'] = work_name\n",
    "    work_info['Work_CV'] = work_cv\n",
    "    work_info['Work_Genre'] = work_genre\n",
    "    work_info['Work_Tag'] = work_tag\n",
    "    work_info['Release_Date'] = release_date\n",
    "\n",
    "    work_list.append(work_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_list = []\n",
    "\n",
    "for i in range(len(archive_list)):\n",
    "    search_code = archive_list['RJ_Code'][i]\n",
    "    try:\n",
    "        dlsite_info_extract(archive_list)\n",
    "    except:\n",
    "        error_rj = archive_list['RJ_Code'][i]\n",
    "        error_list.append(error_rj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "sale_list = []\n",
    "\n",
    "async def main():\n",
    "        browser = await pyppeteer.launch()\n",
    "        page = await browser.newPage()\n",
    "        page_path = 'https://www.dlsite.com/maniax/work/=/product_id/{}.html'.format(search_code)\n",
    "        await page.goto(page_path)\n",
    "\n",
    "        page_content = await page.content()\n",
    "        page_source = BeautifulSoup(page_content, 'html.parser')\n",
    "        try:\n",
    "                sale_count = page_source.find('dt', text = '販売数：').find_next_sibling('dd').text.replace(',' , '')\n",
    "        except:\n",
    "                sale_count = page_source.find('dt', text = '総販売数：').find_next_sibling('dd').text.replace(',' , '')\n",
    "        sale_info = {}\n",
    "\n",
    "        sale_info['RJ_Code'] = search_code\n",
    "        sale_info['Sale_Count'] = sale_count\n",
    "        sale_list.append(sale_info)\n",
    "        await browser.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "nest_asyncio.apply()\n",
    "\n",
    "for i in (range(len(archive_list))):    \n",
    "    try:\n",
    "        search_code = archive_list['RJ_Code'][i]\n",
    "        asyncio.get_event_loop().run_until_complete(main())       \n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "sale_list = pd.DataFrame(sale_list)\n",
    "work_list = pd.DataFrame(work_list)\n",
    "error_list = pd.DataFrame(error_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_list = pd.merge(archive_list, work_list, how = 'left', on = 'RJ_Code')\n",
    "combine_list = pd.merge(combine_list, sale_list, how = 'left',on = 'RJ_Code')\n",
    "combine_list['Sale_Count'] = [re.findall(r'[0-9]{1,10}', x) for x in combine_list['Sale_Count']]\n",
    "combine_list['Sale_Count'] = [max(x) for x in combine_list['Sale_Count']]\n",
    "combine_list['Sale_Count'] = combine_list['Sale_Count'].astype(int)\n",
    "\n",
    "output_list = pd.concat([old_list, combine_list]).reset_index().drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_time = datetime.now().strftime('%Y-%m-%d')\n",
    "writer = pd.ExcelWriter('archive_list_{}.xlsx'.format(date_time))\n",
    "output_list.to_excel(writer, sheet_name = 'Sheet1')\n",
    "error_list.to_excel(writer, sheet_name = 'Sheet2')\n",
    "writer.save()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fbc4b942126ba9087ddc50b773fb3cf6b719b61dbd2d8474e08df5dd5f8c30b1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
